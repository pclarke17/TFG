# üé• Comunicaci√≥n Multimedia en Realidad Extendida  
### Trabajo de Fin de Grado 

Este repositorio contiene la implementaci√≥n completa del Trabajo de Fin de Grado **‚ÄúComunicaci√≥n multimedia en realidad extendida‚Äù**, cuyo objetivo principal es explorar y dise√±ar un sistema capaz de **integrar v√≠deo, audio y comunicaci√≥n en tiempo real dentro de entornos 3D interactivos basados en WebXR y A-Frame**.

El proyecto aborda dos **casos de uso fundamentales**:

---

## üü¶ Caso de uso 1: Visualizaci√≥n multimedia y retransmisi√≥n hacia OBS

Este caso de uso muestra c√≥mo integrar v√≠deos, c√°mara del usuario y contenido tridimensional dentro de una escena A-Frame, y c√≥mo transmitir dicha escena en tiempo real a **OBS Studio** mediante un servidor WHIP desarrollado en Python.

La escena funciona **por s√≠ sola**, sin necesidad de OBS ni del servidor WHIP.  
La integraci√≥n con OBS es **opcional** y solamente se requiere si deseas retransmitir la escena o utilizarla como fuente de v√≠deo en directo.

---

# üåê 1. Ejecutar la escena desde GitHub Pages (sin instalaci√≥n)

La escena puede visualizarse directamente desde:

üëâ **https://pclarke17.github.io/TFG/Caso_1

Esto permite:

- reproducci√≥n de v√≠deos como texturas 3D  
- visualizaci√≥n de la c√°mara del usuario dentro de la escena  
- navegaci√≥n libre en un entorno WebXR  

‚ö†Ô∏è **IMPORTANTE:**  
La retransmisi√≥n hacia OBS no funciona desde GitHub Pages.  
Para ello es necesario ejecutar el servidor WHIP en local (ver secci√≥n 3).

---

# 2. Ejecutar el Caso de Uso 1 en local

Para lanzar la escena con todas sus funciones:

### ‚úî Servir la escena A-Frame

La escena se puede servir desde la propia URL de GitHub Pages.

# 3. Generar certificados HTTPS (requerido SOLO si quieres usar OBS)

El servidor WHIP funciona exclusivamente por HTTPS, ya que WebRTC no permite conexiones inseguras fuera de localhost.

Para ejecutarlo, necesitas generar un certificado autofirmado:

openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes

Esto crear√°:

cert.pem

key.pem

Col√≥calos dentro del archivo whip_server.py y en la misma carpeta donde se encuentre el archivo:

  # HTTPS con la ruta de tus certificados
    ssl_ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
    ssl_ctx.load_cert_chain(
        "/Users/pabloclarke/Documents/TFG/Video/cert.pem",
        "/Users/pabloclarke/Documents/TFG/Video/key.pem"
    )
    
‚úî Si NO deseas enviar la escena a OBS:

No necesitas generar certificados ni ejecutar el servidor WHIP.

# 4. Arrancar el servidor WHIP (opcional)

Si deseas enviar v√≠deo a OBS, ejecuta:

python3 whip_server.py


En el terminal deber√≠as de ver: 

üöÄ WHIP HTTPS escuchando en https://0.0.0.0:8080/whip
üíæ Enviando se√±al en vivo a OBS por UDP ‚Üí udp://127.0.0.1:6000


Este servidor recibe la se√±al WebRTC de A-Frame, la procesa y la reenv√≠a a OBS en formato MPEG-TS.

# 5. Configurar OBS Studio (opcional)

Solo necesario si quieres transmitir la escena.

A√±adir fuente ‚Üí Captura de entrada multimedia

Elegir Red (URL)

Introducir:

udp://127.0.0.1:6000


Ajustar b√∫fer (200‚Äì400 ms recomendado)

![](assets/Config_OBS.gif)

Si todo est√° configurado correctamente, la c√°mara del usuario, los v√≠deos 3D y el entorno de la escena aparecer√°n en OBS en tiempo real.

![](assets/Escena_OBS.gif)

(Si la escena no se ve en OBS y est√° todo corriendo, refresca la p√°gina donde estes lanzando la escena)

--------------------------------------------------------------------------------------------------------------------------------------------------------------

# üîó WebRTC + Videoconferenecia en A-Frame

Este proyecto permite realizar una **videollamada bidireccional** entre dos usuarios utilizando **WebRTC** y visualizando el v√≠deo dentro de una escena **A-Frame** en 3D/VR.

![](assets/Videoconferencia.gif)


## ¬øC√≥mo funciona?

1. **Captura del v√≠deo y audio local** con `getUserMedia()`.
2. Se crea una conexi√≥n `RTCPeerConnection` y se usa **WebSocket** para intercambio de se√±ales (SDP/ICE).
3. El v√≠deo local se asigna a una textura sobre un `<a-plane>` en A-Frame.
4. El v√≠deo remoto se recibe, se dibuja en un `<canvas>`, y ese canvas se usa como textura para otro `<a-plane>`.
5. Se crea una experiencia inmersiva estilo "reuni√≥n en el metaverso".

## Estructura del Proyecto

```
üìÅ videoconferencia-webrtc/
‚îú‚îÄ‚îÄ index.html              # Escena A-Frame con planos de video local y remoto
‚îú‚îÄ‚îÄ webrtc.js               # L√≥gica WebRTC + conexi√≥n WebSocket + texturizado
‚îú‚îÄ‚îÄ server.js               # Servidor WebSocket seguro (WSS) con Node.js
‚îú‚îÄ‚îÄ cert/                   # Certificados auto-firmados para HTTPS/WSS
‚îÇ   ‚îú‚îÄ‚îÄ cert.pem
‚îÇ   ‚îî‚îÄ‚îÄ key.pem
```

## Requisitos

- Node.js (v16+)
- HTTPS local habilitado (auto-signed certificate)
- Navegadores compatibles con WebRTC: Chrome, Firefox, Edge...

## C√≥mo iniciar

```bash
# Instala dependencias (si usas express o similar)
npm install

# Lanza el servidor seguro
node server.js
```

Abre en el navegador:

```
https://<tu-ip-local>/
```

Ejemplo:

```
https://192.168.1.141/
```

Luego abre otro dispositivo/navegador con la misma URL.

## üéÆ Controles

- ‚úÖ Transmisi√≥n de c√°mara y micr√≥fono.
- üé• Los v√≠deos se renderizan en planos 3D dentro de la escena A-Frame.
- üîä El audio se reproduce desde los elementos de video autom√°ticamente.

## üì∏ T√©cnicas usadas

| Tecnolog√≠a | Rol |
|-----------|------|
| WebRTC    | Comunicaci√≥n P2P de audio/v√≠deo |
| WebSocket | Canal de se√±alizaci√≥n (SDP, ICE) |
| A-Frame   | Motor VR para visualizaci√≥n 3D de la videollamada |
| HTML5 Video & Canvas | Captura de v√≠deo y texturizado |
| HTTPS + WSS | Comunicaci√≥n segura necesaria para WebRTC en producci√≥n |

## üõ°Ô∏è HTTPS/WSS en local

Usamos un certificado auto-firmado para desarrollo:

```js
// server.js (extracto)
const server = https.createServer({
  key: fs.readFileSync("./cert/key.pem"),
  cert: fs.readFileSync("./cert/cert.pem"),
}, app);

const wss = new WebSocket.Server({ server });
```

Puedes generarlo con:

```bash
mkdir cert
openssl req -x509 -newkey rsa:4096 -keyout cert/key.pem -out cert/cert.pem -days 365 -nodes
```

## Qu√© esperar una vez dentro de la escena.

Una vez se acceda a la escena, nos encontraremos con distintos botones de car√°cter HTML, en los que podremos apagar/encender el micr√≥fono y la c√°mara, elegir qu√© c√°mara se va a transmitir y con la que el otro usuario nos ver√° y elegir el fondo de la escena 3D.

![](assets/botones_escena_videoconferencia.gif)

En cuanto a las c√°maras, tendremos dos disponibles, la c√°mara de la escena y la webcam del navegador. Este punto est√° pensado para dispositivos donde no se puede acceder a sus c√°maras propias, como es el caso de las gafas de realidad virtual Meta Quest 3, donde se realizaron las pruebas de visionado de la escena.

---

##  Componentes principales del repositorio

El proyecto se estructura en diversos m√≥dulos coherentes con la memoria:

- **`video-canvas-texture.js`**  
  Permite usar v√≠deos locales o remotos como texturas din√°micas.

- **`camera-canvas-texture.js`**  
  Captura la c√°mara del usuario y la integra en la escena como textura.

- **`OBS.js`**  
  Captura el punto de vista del usuario y establece una sesi√≥n WHIP para enviar v√≠deo hacia OBS.

- **`whip_server.py`**  
  Servidor Python basado en `aiortc` y `PyAV` que recibe flujos WebRTC y los retransmite a OBS mediante MPEG-TS/UDP.

- **`index.html`**  
  Escena de demostraci√≥n que integra todos los componentes del sistema.

---

##  Tecnolog√≠as utilizadas

- **A-Frame** y **Three.js** para la construcci√≥n de entornos WebXR.  
- **WebRTC** para captura, transporte y comunicaci√≥n audiovisual.  
- **WHIP (WebRTC-HTTP Ingestion Protocol)** para ingesti√≥n del flujo hacia el servidor.  
- **OBS Studio** para visualizaci√≥n y retransmisi√≥n.  
- **Python + aiortc + PyAV** para procesar v√≠deo y reenviarlo como MPEG-TS.  

Estas tecnolog√≠as permiten combinar XR, comunicaci√≥n en tiempo real y producci√≥n multimedia en un mismo sistema Web.

---

## üéØ Finalidad del proyecto

El TFG demuestra c√≥mo es posible **integrar canales multimedia complejos en un entorno XR accesible desde el navegador**, habilitando aplicaciones como:

- Streaming inmersivo  
- Telepresencia 3D  
- Escenarios de producci√≥n audiovisual interactiva  
- Espacios colaborativos WebXR con v√≠deo en tiempo real  

---
